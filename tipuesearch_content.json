{"pages":[{"text":"By day and often by night, I am a biophysicist working at a major research institution in the Washington, D.C. area. I study the motions of biomacromolecules called enzymes, which play import roles in normal organismal function and in the malfunction that occurs during disease states. Using nuclear magnetic resonance (NMR) spectroscopy, my technique of choice, these motions can be quantitated in various ways with atomic resolution. Outside of lab, I enjoy many other activities: programming in python, all things Apple, running, Kansas basketball (Go Jayhawks!), my collection of cashmere sweaters, and a good mixed drink.","tags":"misc","loc":"http://www.themodernscientist.com/pages/about.html","title":"About"},{"text":"You may have noticed all has been quiet on the blog front from me lately. There are several reasons for this, 1 but I can assure you it isn't for lack of things to write about. Today, I'm happy to share with you one of the projects that has been keeping me busy. I am writing a book about one of my favorite topics: Python! The book is entitled \"Unix and Python to the Rescue!\" and you can read more about it on the official website . As you will notice , I'm not writing the book alone. I am fortunate to be working with Keith Bradnam and Ian Korf, who are both seasoned veterans of the computational book authorship world. 2 Keith and Ian work at the UC Davis Genome Center, where Keith is an Associate Project Scientist and Ian is a Professor. You can read more about Keith, including his announcement of our book on his excellent blog, ACGT . Do we really need another book on Python? There are quite a few books on the topic of Python programming, many of which are excellent, so you may be asking yourself why we need another one. Keith, Ian, and I asked ourselves this when we discussed writing the book. However, I believe the goals of this book, which I've paraphrased from the book's announcement, fill a niche in the Python programming world: Introduce both Unix & Python assuming no prior knowledge of either Include both basic and more advanced topics that are relevant to scientists Whenever possible, make topics \"digestible\" by introducing only one new concept at a time Maintain an engaging and fun style For a book with this focus, I think it is particularly important to cover both Unix and Python because it's nearly impossible to use the later with some knowledge of the former. And there are many times when a few Unix commands can provide a quick answer to help you decide if more in-depth analysis with Python is appropriate. Why should life scientists learn to code? Another great question. Scientists are busy people and there are many data analysis tools available that don't require learning how to program. However, it is my belief--based on my own experience--that using a prefabricated tool, such as a spreadsheet or graphing program, inherently limits you to someone else's idea of what analytical questions you should be asking about your data. In today's scientific world, the amount and type of data we need to understand changes rapidly, and these programs can quickly become limiting. By taking the time to learn a set of basic tools that can be combined in limitless ways, 3 you empower yourself to ask the kinds of analytical questions you want to ask about your data. I also strongly believe in using open source tools, like Unix and Python, because of their accessibility and relative permanence. I have personally been faced with the decision of how to proceed with data analysis when university administration failed to renew a software license before it expired. 4 I have also assisted other scientists who've had data trapped in an unreadable file format because they no longer have access to the program that created the files. I think situations such as these are unacceptable. Even if Python development ceased completely tomorrow, 5 the code would still compile and run on computers for several years to come, allowing time to transition to something new. More importantly, all your data and analyses will remain in an accessible (readable) format indefinitely. What now? Mostly lots of writing and editing! I will also be joining Keith in tweeting from the @rescuedbycode Twitter account. We look forward to sharing Python tips and chatting with you there. Nothing eats up your free time like moving to a new city and submitting five publications, all in one year. ↩ Keith and Ian wrote \"Unix and Perl to the Rescue!\" , which is in some ways a cousin to our current efforts. ↩ This is part of the Unix philosophy . ↩ This experience is actually what prompted me to learn Python. Fortunately, I already had some programming knowledge and was at a position in my career where I was able to spend a little time learning a new language. ↩ I certainly hope this never happens, but for the sake of exploring worst case scenarios, let's consider it. ↩","tags":"misc","loc":"http://www.themodernscientist.com/posts/2015/2015-07-22-throwing_the_book_at_your_data/","title":"Throwing the Book at Your Data"},{"text":"NOTE: If you're using passwords in shell scripts, see Daniel Jalkut's reply below about using OS X's built-in security command instead of his AppleScript library. One of my goals for the new year 1 is to be more security minded in my use of technology. This is a broad statement, but I have some very specific points in mind, including more regular use of a self-hosted VPN (the topic of a future blog post) and avoiding the bad habit of using passwords in shell scripts (the topic of this blog post). The use of security credentials, such as a password, is an integral part of life with technology. For those of us who like to automate things, the need often arises to supply such credentials in a script. The simplest, and least secure, way to do this is to enter the password in the script in plain text form. Having done this myself and seen countless other people who are way better at this automation thing than me do the same , I know it is easy to do. I'm certainly not here to lecture anyone about best practices, but there is another option and it's not that difficult to use. This method involves a little AppleScript and Daniel Jalkut's excellent utility, Usable Keychain Scripting , with the latest version available here . I don't see much mention of Usable Keychain Scripting online, so I thought a tutorial would be a handy way to start the new year. 2 Motivation for Usable Keychain Scripting Daniel's blog posts explain his personal motivations for writing and updating Usable Keychain Scripting, but I first discovered the application when Apple removed keychain scripting from Lion, thus making it impossible to access keychain entries with AppleScript. His utility fills that niche for me, though as mentioned, I don't use it as often as I should. The general idea is to create a specific keychain entry with a title and password in one of your keychains using Keychain Access 3 . Then the password contained in this entry is accessed using the AppleScript library provided by Usable Keychain Scripting. AppleScript can be called from many languages, including the shell, thus allowing the password to be retrieved when needed. 4 Create a keychain password The first step is to create a password entry in Keychain Access. The main consideration here is that although multiple keychain entries can have the same name, it's difficult (and more work) to distinguish between them in an AppleScript. Thus, it's best to ensure the entry has a unique name. Here's an example I created to mount the partitions on our Drobo, called KUPHOG-NAS: 5 Configure Usable Keychain Scripting Before Usable Keychain Scripting can be called from a shell script, some setup is required. I find it easiest to do this in Script Editor. First, Usable Keychain Scripting has to be downloaded and installed in your computer's Applications directory, if this hasn't been done already. Next, the program's AppleScript dictionary has to be installed. This is done by opening the Script Editor's Library window (located in the Window menu) and then clicking on the plus sign. This opens a window to the Applications directory, where Usable Keychain Scripting should be selected. When finished, the program will appear in the Library window, like this: Then the Usable Keychain Scripting AppleScript library should be tested within Script Editor. This is important because your login password has to be entered the first time this AppleScript library is accessed, and the password entry window doesn't always work from a shell script. Here's a sample AppleScript that accesses the password created for the Drobo above: tell application \"Usable Keychain Scripting\" set myPassword to password of first keychain item of keychain \"/Users/mlgill/Library/Keychains/login.keychain\" whose name is \"KUPHOG-NAS\" end tell As is probably obvious, this password was created in the login keychain for my account in Keychain Access. When this is the case, a simpler alternative can also be used: tell application \"Usable Keychain Scripting\" set myPassword to password of first keychain item of the current keychain whose name is \"KUPHOG-NAS\" end tell When either of the AppleScripts is executed, the desired password will be returned. This indicates everything is working: Incorporating Usable Keychain Scripting in a shell script The last step is using your new toy in a shell script. Continuing with the Drobo example, here's how to mount a drive partition from the command line: #!/bin/sh NAS_ADDRESS = 'KUPHOG-NAS' USERNAME = 'Michelle' NAS_MOUNTPOINT = 'TimeMachineBackup' # Execute the AppleScript to retrieve the password PASSWORD = ` osascript << 'END' tell application \"Usable Keychain Scripting\" set myPassword to password of first keychain item of current keychain whose name is \"KUPHOG-NAS\" end tell END ` if [[ ! -e /Volumes/ $NAS_MOUNTPOINT ]] ; then mkdir /Volumes/ $NAS_MOUNTPOINT fi mount_smbfs smb:// $USERNAME : $PASSWORD @ $NAS_ADDRESS / $NAS_MOUNTPOINT /Volumes/ $NAS_MOUNTPOINT That's it! Here's to a more secure 2015! I dislike the absolutism of the word resolution, but call it that if you prefer. ↩ Contrary to some discussion I've seen, Usable Keychain Scripting works on Yosemite (and presumably also Mavericks). It seems there are some changes to the syntax though. ↩ I'd prefer to use 1Password for this task, but there is not a script library that works with 1Password that I know of. ↩ I can imagine there are insecurities associated with Usable Keychain Scripting, but it is certainly more secure than plain text. Use common sense here. ↩ Yes, my husband and I named our Drobo after our allegiance to our alma mater. Rock Chalk, Jayhawk! ↩","tags":"misc","loc":"http://www.themodernscientist.com/posts/2015/2015-01-04-secure_password_use_in_scripts/","title":"Secure Password Use in Scripts"},{"text":"I'd like to follow up on a previous post covering BitTorrent Sync . In this post, I mentioned privacy is one of the advantages afforded by BitTorrent Sync over traditional cloud storage options, such as Dropbox. Like most cloud storage options, data are encrypted during transmission with BitTorrent Sync. 1 Once written to a hard drive, though, these files are often not encrypted. This is the case for BitTorrent Sync and many other cloud storage options. 2 For BitTorrent Sync, this issue is of limited concern if all peers are under your control. However, it may be desirable to utilize peers to which others may have access, such as a virtual private server (VPS). In the previous post, I mentioned using a VPS to help guarantee a synchronized peer was always accessible. In these situations, it is desirable to add additional privacy by selectively encrypting data on such peers. Previously, I didn't think peer data encryption was possible (yet). As I have since discovered, the recently added BitTorrent Sync API enables the encryption of torrent data on selected peers. The BitTorrent forums also describe how to enable this encryption without using the API, which eliminates the need to be issued an API key. Encryption for Existing Torrents I won't repeat the above forum instructions for encrypting torrents without using the API, but it is useful to describe how existing torrents were converted to encrypted versions. I would also like to share some observations about how various BitTorrent Sync features apply to encrypted peers. Broadly, the conversion process involves removing existing torrents and then reinstating them with an adjusted shared secret. For unencrypted peers, the existing torrent files will be reindexed automatically so minimal synchronization is required. Torrents on encrypted peers will need to be resynchronized since the existing files are not encrypted. Unencrypted Peer Setup Before torrent conversion, all peers were fully synchronized and an unsynchronized backup of each of the torrents was created. 3 After backing up the files, the existing shared secret was noted for each of the torrents that would be encrypted. Then the torrent instances—but not the files themselves—were deleted from each of the peers. For each unencrypted peer, the torrent instance was recreated with the first letter of the shared secret changed from an A to a D , as described in the aforementioned forum directions. Each peer was allowed to completely reindex all files associated with a torrent before adding another peer into the mix. Encrypted Peer Setup The process was slightly more complicated for peers that contained an encrypted version of the torrent. First, the existing unencrypted files were moved to a different location, as a temporary backup, and empty destination directories were created for the torrents. By definition, encrypted peers contain read-only copies of the torrent. So, generating the correct shared secret required noting the read-only shared secret from one of the existing unencrypted peers. To convert this to an encrypted read-only secret, the first letter was changed from an E to an F and only the first 33 characters were used. After setup, the encrypted peer was allowed to synchronize the torrent. Unlike the unencrypted peers, quite a few errors were generated during this process in the log file of the encrypted peer. However, synchronization did complete, and the encrypted torrent was successfully used as the sole restore point to an unencrypted torrent on a new peer. Thus, the log errors likely refer to recoverable issues that may even be sorted out as this feature matures. Other Notes About Encryption I didn't measure the time required for the encrypted peer to fully synchronize, but I don't think the process took longer than it previously had for the same unencrypted torrent on this machine. 4 According to forum discussion , this process may take 2–3 times longer for lower end hardware, such as that containing an ARM processor, but little difference is noted for higher end computers. Torrent encryption may also slow down the listing of files on mobile devices. The resulting encrypted torrent maintained the same folder structure as the unencrypted peers, except that all file contents and file/directory names were encrypted. I suspect the directory structure is maintained in effort to keep encrypted peers compatible with other API features, such as selective file synchronization. File exclusion entries in .SyncIgnore don't seem to work, which I assume is because the file and directory names can't be matched since they are encrypted. Because the nature of the files cannot be discerned, I decided there was no point in enabling the archive feature on the encrypted peer. One concern with utilizing a seemingly unsanctioned method is that future software updates may disable loopholes allowing encryption to work without requiring the API. It is even possible such updates could cause file corruption. There are three reasons I'm not worried about either of these scenarios. First, I make incremental unsynchronized backups of all my files using an rsync -based script, 5 so there is always a recent, working copy to roll back to. Second, the forums mention encryption will eventually be added to the main program once the aforementioned speed issues are addressed. Third, the encrypted peer is by definition read-only, so (in theory) it can't make any changes to files in the torrents. Thus, I suspect it would, at worst, stop being able to connect to other peers if such software changes were made. As always, you should make your own decision about how to proceed. Happy encrypted synchronizing! According to the web site, BitTorrent Sync uses AES-128 in counter mode. Security and encryption aren't my areas of expertise. Constructive, informative comments on this topic are welcome. ↩ Some cloud services do offer end-to-end encryption, such as SpiderOak . However, these services still use a fee schedule similar to that of Dropbox, making them very expensive for storing large amounts of data. ↩ Remember that synchronization is not the same thing as backup. If error(s) are introduced to a set of synchronized files, such as those in a torrent, they will be propagated across all synchronization sources resulting in file corruption. ↩ There are many factors that affect this rate, including the fact that three peers were already synchronized when the encrypted peer was setup. Thus, I didn't feel it was worth timing the encrypted synchronization. ↩ I plan to cover this rsync script in a blog post in the near future. ↩","tags":"misc","loc":"http://www.themodernscientist.com/posts/2014/2014-02-21-encryption_of_bittorrent_sync_peers/","title":"Encryption of BitTorrent Sync Peers"},{"text":"My research requires that I work in multiple locations: in the lab, at a multi-institution shared instrument facility, and sometimes in my fuzzy slippers at home. Having my data and processing scripts updated on whatever computer I happen to be using is critical to my ability to get work done. Since these files are too large for Dropbox storage to be economical, I have previously relied on programs such as Unison and ChronoSync . Unfortunately, these tools require some manual effort 1 to ensure my ever-growing research directory is updated when switching computers, a process that sometimes happens multiple times per day. Having endured this daily nuisance of file synchronization for several years, I was thrilled to discover the recent release of BitTorrent Sync , which relies on the BitTorrent protocol. I used torrents in my graduate school days to download Linux distributions because I found this method was generally faster than using a web browser. Applying this protocol to the synchronization of files is, to me, a natural extension of its powerful feature set. Before delving further into the setup of BitTorrent Sync, it is important to understand how the BitTorrent protocol works. Traditional cloud storage systems, such as Dropbox, utilize a centralized, master server to which all clients upload and download files. The BitTorrent protocol instead allows every client to upload and download to all other clients. This decentralized, peer-to-peer model requires the user to provide the devices that will serve as synchronization points (peers), but that requirement also has many advantages. In situations where large file sets are synchronized, it is often more cost efficient to provide your own hardware, which you may already own, than pay the fee for increased cloud storage. The BitTorrent protocol also allows users to avoid storing data on servers belonging to someone else, potentially making BitTorrent Sync more private. BitTorrent Sync has been robust and very fast based on my experience thus far. It has tremendous potential for the synchronization and sharing of large data sets, such as those generated by scientists, within a single research group. Perhaps more importantly, BitTorrent Sync can make sharing data with other research groups through open data initiatives, such as Academic Torrents , much easier. BitTorrent Sync Setup on a Mac The Mac BitTorrent Sync application is simple to setup. The first time a folder to be synchronized is added to your list of torrents, BitTorrent Sync has to generate a shared secret code. Anyone who has this code can download and modify files in the torrent, so guard it carefully. Additional instances of this torrent should use the previously generated shared secret. Based on my experience, BitTorrent Sync will try to use existing files for the initial synchronization, so it is possible to speed up this process by pre-populating peer directories with updated copies of the file set. There are some additional options for controlling BitTorrent Sync that don't reside within the application. Inside each synchronized folder is a file called .SyncIgnore and a directory called .SyncArchive . The former contains a list of files and folders that will be ignored during synchronization, with support for basic file globbing, such as ' * ' and ' ? '. The .SyncArchive directory contains old versions of all files that have been changed or deleted. The .SyncArchive option seems to keep versions indefinitely and can optionally be disabled within the application on each of the peers. Other Features and Comparison to Dropbox The features offered by BitTorrent Sync are similar to those of Dropbox in more ways than just the real-time synchronization of files. And there are also some important differences. The previously mentioned options to exclude files from synchronization and store modified or deleted files are similar to Dropbox's selective synchronization and versions features, respectively. The inclusion of file globbing in BitTorrent Sync's file exclusion implementation makes it more powerful than Dropbox's. On the other hand, I think Dropbox's file versioning system, which includes a web browser component, is more user friendly. Like Dropbox, files can also be shared with others using BitTorrent Sync, but it is only possible to do so as a torrent--there is no official option for downloading files through a web browser. Additionally, a share from BitTorrent Sync must include the entire contents of the torrent. However it is possible to restrict these shares to read-only access and set a time limit of 24 hours for downloading. Perhaps the most important--and very subtle--difference between BitTorrent Sync and Dropbox is that BitTorrent Sync does not support extended attributes. This is not an issue for me as most of my research files are generated on Linux filesystems, which do not regularly use extended attributes. Those files that do have extended attributes, mostly generated by Microsoft Office and iWork, don't seem to actually use them. I have verified this through years of synchronizing files using methods that do not support extended attributes. Usage scenarios differ, however, so this issue should be tested carefully. For example, heavy users of file tagging in Mavericks or PDF annotations in Skim , both of which rely on extended attributes, may find that BitTorrent Sync does not suit their needs. Additional BitTorrent Sync Servers Though my primary need is the synchronization of files between two Macs, there are advantages to having additional file servers. A minimum of one fully updated peer is required for synchronization, so increasing the number of servers adds robustness to the system. Similarly, additional peers provide more download sources during synchronization, which can make this process faster. For these reasons, I am also running BitTorrent Sync on a web server and on a Drobo 5N. The setup of BitTorrent Sync on these two clients is more complicated than on the Mac, so I have outlined both processes below. Setup on a Web Server Based on the recommendation of several users on the BitTorrent Sync forums, I purchased a virtual private server from a backup-focused service called Backupsy . The service offers a variety of configurations at a very reasonable cost. 2 I decided to use the default BitTorrent Sync command line program for Linux so I could configure everything exactly as I wished. Those who are familiar with the Debian package management system might prefer the user-maintained package . The BitTorrent Sync program, called btsync on Linux, can create a default text configuration file. I used this as well as online resources to get started. The Linux version of BitTorrent Sync comes with a web interface enabled by default, which provides a convenient GUI for managing torrents. However, I opted to disable it since the only available security settings are a username and password, which could theoretically be determined by brute force methods. 3 There were two \"gotchas\" I discovered while setting up my web server: First, it seems the destination directory must exist before starting BitTorrent Sync otherwise no files will be downloaded. Second, the BitTorrent Sync web interface cannot be run if the shared_folders option is used within the configuration file. It is possible to switch between the two methods without resetting the synchronization state by modifying the configuration file (see below) and restarting BitTorrent Sync. Both options cannot be run at once, though. 4 Here is my configuration file for BitTorrent Sync on my Backupsy server. The first line of the file contains an example of how the configuration file is loaded as a BitTorrent Sync instance. The web interface is setup in the webui section. Alternatively, the shared_folders section is used if webui is disabled, as has been setup below. // /home/user/btsync/bin/btsync --nodaemon --log file --config /home/user/btsync/conf/my_btsync.conf // web interface is disabled { \"device_name\": \"Phog\", \"storage_path\" : \"/home/user/btsync/sync\", \"listening_port\" : 0, \"check_for_updates\" : false, \"use_upnp\" : false, \"download_limit\" : 0, \"upload_limit\" : 0, \"disk_low_priority\" : true, \"lan_encrypt_data\" : true, \"lan_use_tcp\" : true, \"rate_limit_local_peers\" : false, \"folder_rescan_interval\" : 600, \"webui\" : { // \"listen\" : \"0.0.0.0:8888\", // \"login\" : \"xxx\", // \"password\" : \"xxx\" }, \"shared_folders\": [ { \"secret\":\"xxx\", \"dir\":\"/home/user/research\", \"use_relay_server\":true, \"use_dht\":false, \"search_lan\":false, \"use_sync_trash\":true } ] } Setup on a Drobo 5N BitTorrent Sync is also compiled for ARM processors, which means it will run on Drobo storage devices. Setting up BitTorrent Sync on a Drobo is a little more complicated than a Linux server since the Drobo operating system doesn't have ssh and various unix utilities installed out of the box. The DroboPorts website contains good instructions for setting up dropbear for ssh access, and vim for remotely editing text files. To setup BitTorrent Sync, I roughly followed these instructions. Since the Drobo is only accessible within my home network, I am using the BitTorrent Sync web interface for now. Other BitTorrent Sync Notes There are mobile (iOS and Android) versions of BitTorrent Sync available. Much like their Dropbox counterparts, these applications refresh a file listing for associated torrents when opened but only download files on demand. Torrents can be added by scanning a QR code generated by the desktop application, which is both an awesome use of QR codes and easier than typing the shared secret on a mobile device. The mobile BitTorrent Sync application has an option to automatically backup pictures from the device. Currently, it is not possible to check the status of torrents from the command line. This can only be done using the BitTorrent Sync web interface. In the future, I'd love to see a command line option added so I can create an automated method to check the status of BitTorrent Sync on my web server. I currently use a derivation of an rsync-based script, called rsnapshot , to imitate the incremental backups created by Apple's Time Machine because I have had many issues with Time Machine in the past. This script was formerly used to synchronize files from my laptop to the Drobo when I was at home. Now that the Drobo always contains an updated copy of my files, I am experimenting with running rsnapshot directly on the Drobo and synchronizing files directly from my torrent directory. Various automation programs could be used to run these programs at regular intervals. However, ssh tunneling to my computer in lab is sometimes problematic due to university-imposed firewall rules, so I do not feel comfortable assuming an automated synchronization method completed successfully. ↩ There is a promotion code (GOTMEADEAL) which offers a significant discount for the lifetime of the virtual machine. ↩ I can't stress how important security is for a web-accessible server. In the approximately 20 minutes from when Backupsy provisioned my server to the time that I disabled ssh access for root, there were over 50 attempts from a foreign IP address to determine the root password by brute force methods. ↩ The inability to use shared_folders and webui at the same time is mentioned in the BitTorrent Sync manual , but I didn't discover this until after puzzling over the issue for some time. RTFM. ↩","tags":"misc","loc":"http://www.themodernscientist.com/posts/2014/2014-02-06-torrential_file_synchronization/","title":"Torrential File Synchronization"},{"text":"{% notebook EasySyntaxHighlightingWithPygments.ipynb cells[1:2] %} I spend most of my time writing code in text editors 1 that have syntax highlighting and I prefer my snippets similarly highlighted. While there are many syntax highlighting engines and websites in existence, one of the most powerful engines happens to be Pygments , which is python-based, as the name implies. {% notebook EasySyntaxHighlightingWithPygments.ipynb cells[3:] %} This post was written in an IPython notebook, which can be downloaded here , or viewed statically here . Vim and Sublime Text really are the only editors worth using. ↩","tags":"misc","loc":"http://www.themodernscientist.com/posts/2013/2013-10-24-easy_syntax_highlighting_with_pygments/","title":"Easy Syntax Highlighting With Pygments"},{"text":"Previously, I posted about using Growl in combination with Prowl to get remote notifications of experiment progress on both a Mac and iPhone. Later that day, I started thinking about some improvements to the script after a brief Twitter conversation with Seth Brown . 1 The script depends on the remote Mac being always on and reachable from the internet. This is true for my Mac desktop, but it may not be in many other situations, such as when a laptop is involved. In cases such as these, the notification can be sent directly to Prowl from the shell script itself. 2 Posting to Prowl requires only one additional piece of information: a Prowl API key. The API key can be generated and accessed from Prowl's website after logging in. The API key is circled in red below. If there are no active keys, 3 they can be generated on this page as well. Posting to Prowl using an API key is described in the documentation , but it is quite simple and can be accomplished from the command line with curl like this: curl -s --data \\ \"apikey=enter_your_api_key_here&application=Command Line&event=Posting to Prowl\" \\ https://api.prowlapp.com/publicapi/add Prowl's API then returns an xml string containing information about the success or failure of the post attempt: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <prowl> <success code=\"200\" remaining=\"993\" resetdate=\"1382212452\" /> </prowl> According to Prowl's documentation, 1,000 API calls are allowed per hour from a single IP address. That should be plenty for simple status posts. I have also created a new version of the associated shell script that will attempt to ping the remote computer before synchronizing data and sending a Growl notification. If the remote computer is not available, the notification will be posted directly to Prowl. [gist:id=7060718,file=Improved_Growl_Experiment_Status.sh] Have fun! If you are interested in python, data visualization, R, and pretty much every other cool thing on the internet, you should definitely follow him and read his blog . ↩ This alternative could be also be used exclusively instead of Growl. However, I prefer receiving notifications on my Mac if I am actively using it. ↩ I set up my Prowl account so long ago, that I don't recall if the initial API key was active or if I generated it. ↩","tags":"misc","loc":"http://www.themodernscientist.com/posts/2013/2013-10-19-automated_notifications_of_experiment_progress_part_2/","title":"Automated Notifications of Experiment Progress: Prowl Extra Credit"},{"text":"In addition to covering my use of python in research, one of my goals for this blog is to share ways I use various other computational tools to automate basic research tasks. Such an opportunity arose this week with the onset of hardware issues causing one of our laboratory's NMR spectrometers to periodically stop running during a series of multiple day experiments. The instrument is still useable while waiting for a replacement part to arrive, but periodic reboots of the hardware are necessary for the experiment to continue where it left off. Thus, it is critical to know when such a reboot is necessary. Rather than make constant trips to the building where the instrument is located, I rigged up a notification system using some basic unix and Mac tools. The instrument periodically writes data to a file when an experiment is running. So, my solution is a shell script that periodically monitors this file for updates and then sends Growl notifications to my Mac, which is located in another building. 1 Because Growl on my Mac is configured to work with Prowl , a complimentary iOS notification system, 2 I also receive notifications on my phone whenever the remote Mac is idle. As a bonus, I added the option to send the experimental data to my Mac for processing. This solution requires SSH keys to be setup so the spectrometer's computer can login to my Mac when necessary. It also requires the installation of growlnotify , a command line accessory to Growl. [gist:id=6951180,file=Growl_Experiment_Status.sh] The script is written in the Z-shell 3 and can be downloaded here . It asks for several configuration options, ensures the file that is used to track experiment progress exists, and then performs periodic checks on the modification time of this file until the script is halted. The optional transfer of data takes place via rsync 4 . The interval time must be adjusted so that the data file is written to more frequently than it is polled for modifications, otherwise the script will incorrectly indicate the experiment has stalled. There are a few nuances associated with the encoding of the growlnotify string. First, the entire command has to be enclosed in quotes because it is sent through ssh to the remote Mac. Additionally, each of the arguments passed to growlnotify, such as the contents of the $message_string variable, must themselves be enclosed in quotes when executed on the remote Mac. I prefer to use single quotes for the growlnotify command and double quotes for the individual arguments. However, variables, such as $message_string , are not expanded within single quotes, so they must appear outside of the single quotes, as can be seen above. The contents of $message_string must still be enclosed in double quotes, which appear before and after the respective single quotes flanking $message_string . Once I start my experiment on the spectrometer, I setup this script to run indefinitely. An added bonus is that it will notify you when the experiment has finished. If the instrument writes progress information to a plain text log file, this file can be queried and more detailed status information that can be included in the $message_string . Here is an example 5 of the Prowl status updates I receive on my iPhone. The actual script I use derives additional information from the log file of the NMR spectrometer. This is a script I have been meaning to write for quite some time and I plan to use it, perhaps with less frequent notification times, even after the spectrometer is repaired. VNC could also be used to to check on the experiment, but I prefer a method that also notifies me when I am away from my computer. ↩ There are other notification systems that will also work with Growl. I've also used Boxcar , but I switched to Prowl after Boxcar became unreliable at times. ↩ I believe it will run in Bash with minimal or no modifications; however, if you're not using the Z-shell, you should be . ↩ When using rsync in a script, I prefer the long version of argument names for readability because I never remember what the short versions mean. ↩ With super secret science stuff obscured. ↩","tags":"misc","loc":"http://www.themodernscientist.com/posts/2013/2013-10-12-automated_notifications_of_experiment_progress/","title":"Automated Notifications of Experiment Progress: Combining Shell, SSH, Growl, and Prowl"},{"text":"This IPython notebook builds on the previous blog post which described how to simulate and plot the result of a shaped pulse on magnetization in an NMR experiment. For the purpose of teaching 1 , it can also be useful to visualize the effect of this pulse on the magnetization at each discrete time step of the pulse. Visualizing the time-dependent course of magnetization requires the javascript viewer developed by Jake Vanderplas described here and further demonstrated here . This library has to be installed somewhere in the path searched by Python. NymPy and Matplotlib are also required. {% notebook NMRShapedPulseAnimation.ipynb cells[2:3] %} The steps required to created the Reburp shaped pulse and calculate its propagator have been described in the aforementioned post and are available in the downloadable and static version of this notebook linked to below. Thus, I have jumped directly to the data visualization. {% notebook NMRShapedPulseAnimation.ipynb cells[12:] %} This post was written in an IPython notebook, which can be downloaded here , or viewed statically here . And providing an excuse for me to play with animations in IPython notebooks. ↩","tags":"misc","loc":"http://www.themodernscientist.com/posts/2013/2013-06-14-visualization_of_nmr_shaped_pulses/","title":"Visualization of NMR Shaped Pulses: Fun with Javascript Animation"},{"text":"Bandwidth-selective excitation in NMR is commonly accomplished through the use of shaped pulses. These pulses require careful calibration to ensure power levels and pulse lengths are correctly determined for optimal excitation of only the desired frequency range. Simulating the shaped pulse over a range of frequencies is one way of accomplishing this task. Many spectrometer control programs contain software capable of this (Bruker's TopSpin has ShapeTool and Aglient's VNMRJ has Pbox), but these simulations can also be performed quite easily in an IPython notebook. {% notebook NMRShapedPulseSimulation.ipynb cells[1:39] %} None of my attempts at automatically vectorizing this function were successful. 1 Since the matrix is only 3x3, it is not difficult to calculate each of the nine matrix elements. Their symbolic values can be determined by printing each element of the SymPy function. Note the use of SymPy's simplify function for algebraic simplification. {% notebook NMRShapedPulseSimulation.ipynb cells[40:51] %} As expected, this function is much faster than the original NumPy version. In this case, the speed increase over the improved NumPy version is rather modest. 2 The relative speed of the fortran function will likely grow as the number of points increases, but this is also a lesson about spending time optimizing a particular technique before moving onto something more powerful. (If major improvements can be made to either of the subroutines, then there is also a lesson about being familiar with the nuances of a language.) {% notebook NMRShapedPulseSimulation.ipynb cells[52:] %} Edit: The original version of this notebook contained two errors. The first involved the modification of NumPy ndarray views during matrix multiplication within the faster NumPy function. The second chose vectorComponent from the wrong axis at the conclusion of the faster NumPy function and in the Python wrapper that calls the Fortran function. This resulted in an inversion of the y -axis magnetization. Both errors have been corrected. Thanks to Joshua Adelman for catching the second error. A minor change to the matrix simplification calculation due to an update of the SymPy package was also made, however this change had no effect on the result. Edit: A Cython version of the propagator function provided by Joshua Adelman has been added above. This post was written in an IPython notebook, which can be downloaded here , or viewed statically here . Ideally this function could be vectorized with something like SymPy's lambdify , autowrap , or ufuncify functions or with the Theano package. Unfortunately, lambdify isn't compatible with NumPy arrays. Likewise, autowrap isn't compatible with SymPy's Matrix function yet . I was unsuccessful in getting unfuncify to work with this case, and my MacBook Air doesn't have the graphics card necessary for GPU computing, so I didn't attempt to use Theano. ↩ It would also be interesting to compare the speed of these functions to versions implemented in Numba and Cython . My efforts at implementing this subroutine in Numba were not very successful and I'm not fond of C, so I decided to pass on Cython. ↩","tags":"misc","loc":"http://www.themodernscientist.com/posts/2013/2013-06-09-simulation_of_nmr_shaped_pulses/","title":"Simulation of NMR Shaped Pulses: NumPy vs Fortran"},{"text":"Many have asked about my blog design and how I incorporate IPython notebooks, such as the one used in the previous post . I merely glued all the pieces together for this setup, so to give credit where it is due and to provide a documented how-to for my future self, I've described both blog design and incorporating IPython notebooks into posts. My desire for this blog has always been to have a platform for sharing useful and sometimes interesting information related to my research and to provide an opportunity to learn, which for me means tinkering. As someone who does not have extensive knowledge of CSS or other web-centric languages, I knew I wanted to use a template-based solution rather than coding a website from scratch. However, the inevitable desire to tinker meant that browser-based template options, such as those offered by Wordpress and Blogger, wouldn't suffice. Solutions that compile templates locally, such as Octopress, allow more customization and, thus, seemed like a good option. The downside of Octopress is that it uses ruby, which I don't know. After more searching, I discovered Pelican , which works similarly to Octopress but is written in my beloved Python. Having a blogging engine that speaks the same language as the topic of much of the content I envisioned posting seemed like a natural solution. After settling on a blogging solution, I had to find a Pelican-based template. Having browsed many Octopress blogs, I developed an affinity for the default template used by this engine. Fortunately, a kind soul had converted the Octopress template to Pelican and shared it. Since I prefer lighter tones for websites and the default format of this template is quite dark, I wanted to modify it. I found an excellent tutorial by Aijaz Ansari on customizing this theme within Octopress and was able to apply these changes directly because the CSS portion of this template is identical to the Pelican version. These theme modifications are based on SASS , so I did need to break out my ruby chops to compile 1 the modified theme into CSS 2 . The last step was adding the ability to insert IPython notebooks in blog posts. Fortunately, Jake Vanderplas recently posted about doing so in Pelican. He even created a Pelican extension, called liquid tags , capable of inserting an IPython notebook referenced in a markdown post. If you go this route, please be aware that liquid tags is very new--as of the writing of this post, it is still a pull request on GitHub. Furthermore, liquid tags depends on nbconvert , an IPython utility for converting notebooks to html and other formats, which itself is currently being rewritten. Thus, any efforts in this area will likely have to be duplicated again in the future once these packages stabilize. For the fearless, I have described the installation in more detail here . This requires installation of the compass ruby gem. Once installed, the CSS is compiled by running compass compile from the top directory of the theme (where config.rb is located). The compiled file is created in static/css/main.css of the theme and will be copied to the correct directory upon blog generation with pelican. ↩ The compiled CSS file used for this blog can be downloaded here . ↩","tags":"misc","loc":"http://www.themodernscientist.com/posts/2013/2013-06-02-my_octopelican_python_blog/","title":"My Octopelican Python Blog"},{"text":"My research is focused on biomolecular NMR and, as such, often involves transferring resonance assignments from one multidimensional NMR spectrum to another. In theory this should be a simple task, but it can be extremely time consuming due to small variations in the sample used to acquire the data or in the way the data were acquired. The good news, however, is that it is possible to automate this process using an optimization. Optimization problems, such as aligning x-ray crystallographic models of homologous proteins, are often encountered in structural biology. In the case of a structural alignment, the transformed structure can occupy any set of coordinates, provided the shape of the molecule itself is not changed. The transfer of resonance assignments is different in that individual resonances are either matched with each other or not. The transformation from one set of data onto another is effectively discrete (more specifically, it is binary). This type of optimization is known as \"binary integer programming.\" When I attempted to write a script to perform this type of optimization using python, I found some excellent background reading but very little information on how to implement such a calculation. Being someone who learns by example, I thought it would be useful to share how I setup a simple binary integer programming calculation using two different python libraries 2 that interact with open source solvers written in ANSI C. 1 {% notebook BinaryIntegerProgramming.ipynb cells[1:] %} This post was written in an IPython notebook, which can be downloaded here , or viewed statically here . The two solvers, GLPK and lp_solve, are somewhat old and, it would seem, neither particularly fast or robust compared to more modern implementations , but they are well-tested and more than sufficient for my purposes. ↩ I have used a third python library, OpenOpt , which also interfaces with GLPK. It is not demonstrated here as the syntax is similar that utilized by CVXOPT. ↩","tags":"misc","loc":"http://www.themodernscientist.com/posts/2013/2013-05-29-binary_integer_programming_with_python/","title":"Binary Integer Programming With Python"},{"text":"You are receiving this post because I've migrated my RSS feeds from FeedBurner to URI.LV. I attempted to automatically migrate all subscribers to the new feed but, due to consequences outside my control, that wasn't possible. So, I'd greatly appreciate it if you could resubscribe using the new feed at http://feeds.uri.lv/themodernscientist-rss . Thanks!","tags":"misc","loc":"http://www.themodernscientist.com/posts/2013/2013-05-26-please_update_your_rss_subscription/","title":"Please Update Your RSS Subscription"},{"text":"The coming week is going to be an incredibly busy, but exciting, one for me. Besides having updated my blog so that I am now one of the cool kids with a Pelican -generated blog hosted at GitHub , 1 the following things are also taking place: I will become a parent to an adopted kitty I will become an aunt to a new human I will be hosting my darling sister-in-law who will be visiting me for the first time since I've lived in NYC I will be away most of the week for some academic job interview thing :) Needless to say, my presence online will be scarce. And the list of future blog posts continues to build. 2 For the three or so of you who subscribe via RSS or email (hi, mom!), old posts are likely to show up in your inbox again since the setup of the feed has changed. I apologize for the inconvenience. ↩ Some of these posts will include pictures of the adorable new creatures in my life. ↩","tags":"misc","loc":"http://www.themodernscientist.com/posts/2013/2013-04-07-for_some_this_is_a_busy_week/","title":"For Some, This is a Busy Week"},{"text":"This is, in so many ways, not the topic I envisioned for my second post. Sometimes life has other plans. I knew you were special the moment you leapt into my arms at the cat shelter in New Haven the day we met you. Though we hadn't stopped at the shelter with the intention of adopting, you had chosen us and that's the way it would be. We had just moved far away from our relatives and friends, and you provided roots and a feeling of belonging. With you, we were a family. Our dwelling became a home. We named you Lawrence, in honor of the street in New Haven on which we lived and the nearby shelter where we met you. Coincidentally, it was also the name of the Midwestern town we had just left. The name was quirky and a little too distinguished for a cat, and it would prove to suit your personality exactly. You were a loyal companion throughout the many adventures life brought us. In graduate school, you helped me study for my oral exam, and you were by my side (or on top of my keyboard) when I wrote my thesis. During your time with us, you moved to nine different homes, one of which was a friend's guest room. You endured a drive across the country for one move and, for another, a flight, complete with a stress-filled scene at the security line. You tolerated an extended stay at a Days Inn, where we had to lock you in the bathroom every time we left in case housekeeping came. You took each of these adventures in stride, with the endearing aplomb and dash of absurdity that I'd come to love about you. Occasionally, your adventuresomeness outweighed your bravery, though we never could convince you of that truth. Twice you escaped into the great outdoors. Fortunately, you didn't get far before deciding that hiding under the deck was the quickest way to return to the comforts of home. Your were sometimes mischievous: teaching yourself to open cupboards and doors so you could get into things you weren't supposed to. You were often comical: twitching your tail in excitement and, when we scolded you, cackling in reply to mock us. You were always affectionate: during particularly enjoyable petting sessions, your purr was loud enough to make the cushions vibrate. I loved all of your quirks: the way you stretched your arms out in token resistance when we rubbed your belly; the bobbing of the tabby-striped rings on your tail as you trotted to the door to greet me every evening; the way your gorgeous green eyes twinkled with mischief; the twitching of your tri-color nose as you rubbed it against my cheek to wake me up to feed you; the way you snuggled in bed with Rob after I arose, a daily event that I dubbed \"Bro Time\". The end of your days with us came swiftly and unexpectedly. Your health was excellent, so I envisioned you as a cat whose longevity would be legendary. I was shocked and terrified as we rushed you in a cab to the emergency veterinary clinic the night you suddenly found yourself too weak to get into our bed. It broke my heart to see three people working to stabilize your condition as we left the hospital that night, but I was certain you would return home for many more years of adventures. It was not meant to be. The veterinarian bought you a few hours of reprieve from the bleeding caused by the cancer inside you. We took you home the next day and stuffed you full of all the tuna and affection you could handle. As the day passed, I could see your strength starting to fade. I would have given anything to stop time at that moment and spend a few more days with you. We laid you to rest that night, March 15, 2013. Eleven years, almost to the day, from the moment you first graced our lives. We were devastated by the abrupt end of your time with us, but we were relieved your suffering was brief. Though you were uncomfortable and too weak to walk near the end, you were nothing but the sweet and loving gentleman we knew. The happy times we had together will remain bright in our hearts and minds. Where you are now, we know there is an endless supply of tuna, ear scratches, and Bro Time. Goodbye, dear friend.","tags":"misc","loc":"http://www.themodernscientist.com/posts/2013/2013-03-16-to_my_friend/","title":"To My Friend"},{"text":"After much consternation and hand wringing, I am attempting to revive my blog. I've learned from previous deterrents and now have a clearer vision of the topics I'd like to cover. So, for the time being, I am simply saying \"hello\" and giving those interested the opportunity to subscribe. In the meantime, I leave you with a picture of one my 1 toys: a 900 MHz nuclear magnetic resonance (NMR) spectrometer equipped with a cyropbrobe. This is an example 2 of the instruments I use to collect data. You can learn a little more about me and how I use NMR here . Property of the New York Structural Biology Center but I like to pretend it's mine. ↩ A very nice example. ↩","tags":"misc","loc":"http://www.themodernscientist.com/posts/2012/2012-12-16-hello_part_deux/","title":"Hello, Part Deux"}]}